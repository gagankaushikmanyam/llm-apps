Author: Gagan Kaushik Manyam  
---

# ğŸ§ª LLM Lab â€” A Systems-First Playground for Modern LLM Engineering

**LLM Lab** is a modular, Streamlit-based experimentation environment for learning and demonstrating  
**how real-world LLM systems are designed, debugged, and extended** â€” beyond prompts and demos.

This repository focuses on **system behavior**, not model hype.

It covers:
- supervised fine-tuning
- hallucination mitigation
- RAG-lite grounding
- multi-step orchestration
- tool-based (MCP-style) execution

All examples are:
- **CPU-friendly**
- **fully inspectable**
- **explicit about failure modes**

This is a **learning + research lab**, not a production framework.

---

## ğŸ‘¤ Who This Repository Is For

This repo is designed for:

- **Aspiring AI / LLM Engineers** entering industry roles  
- **Software / ML Engineers** transitioning into LLM systems  
- **Researchers** who want to understand *why* LLMs fail or succeed  
- **Recruiters & hiring managers** evaluating practical system design skills  

If you want to understand:
- why hallucinations happen,
- why prompting is not enough,
- how orchestration actually works,
- how tools change LLM behavior,

this repo is for you.

---

## âœ¨ Design Principles

- ğŸ” Inspectability over magic  
- ğŸ§  Concept-first demos (why things work or fail)  
- ğŸ’» CPU-first, GPU optional  
- ğŸ¯ Reproducibility (explicit seeds)  
- ğŸ§© Plugin-style architecture  
- ğŸš« No hidden datasets, no black boxes  

---

## ğŸ— Architecture Overview

The lab is structured around a **single Streamlit launcher**:

```
app.py
```

Applications are auto-discovered from:

```
applications/
```

### ğŸ”Œ Application Contract

Every app must expose:

```python
APP_NAME = "Human-readable name"
APP_DESCRIPTION = "Optional description"

def run() -> None:
    ...
```

â¡ï¸ Drop a new file into `applications/`  
â¡ï¸ Restart Streamlit  
â¡ï¸ No launcher changes required  

This keeps the system scalable and clean.

---

## ğŸ§  App 1 â€” Hugging Face Fine-tuning (Supervised)

ğŸ“„ **File:** `applications/finetuning.py`

Demonstrates end-to-end supervised fine-tuning of a causal language model using  
Hugging Face Transformers.

---

### ğŸ¯ Task

Logistics email subject line generation from short instructions.

Example:

```
Instruction: Write an email subject for a shipment delayed due to weather.
Subject: Weather Delay: Updated ETA for Shipment (Arrives Tomorrow)
```

---

### ğŸ“Š What This App Shows

- TRUE before vs after comparison  
- Validation loss + early stopping  
- Holdout benchmark (not seen during training)  
- Simple metrics:
  - Exact Match
  - Token-level F1  
- Saved artifacts under:

```
artifacts/finetuning/<timestamp>/
```

---

### ğŸ¤– Models

- `sshleifer/tiny-gpt2` â€” ultra-fast, educational  
- `distilgpt2` â€” higher quality, still CPU-friendly  

âš ï¸ This app performs **full fine-tuning**, not LoRA / QLoRA  
(LoRA / QLoRA are planned extensions.)

---

### ğŸ§  Key Lesson

Fine-tuning:
- improves task alignment
- does NOT inject knowledge
- overfits easily with small data

This app shows what fine-tuning can and cannot do.

---

## ğŸ§  App 2 â€” Hallucinations Lab (Prompting + RAG-lite)

ğŸ“„ **File:** `applications/hallucinations.py`

Demonstrates why hallucinations happen and why grounding with context  
is the only reliable mitigation.

---

### ğŸ”´ Baseline (Free-form)

- No structure  
- No refusal  
- No grounding  

Ask:

```
What year did Isaac Newton invent the smartphone?
```

Result:
- fluent
- confident
- fabricated

This is default LLM behavior.

---

### âš ï¸ Prompting Alone Is Not Enough

JSON-only, refusal, self-consistency:
- improve format
- improve stability
- do NOT guarantee truth

Prompting reduces chaos â€” not hallucinations.

---

### ğŸŸ¢ Context-Only Answering (RAG-lite)

The model:
- may ONLY use retrieved context
- must say `UNKNOWN` if unsupported

This is a minimal RAG system.

---

### ğŸ“š Knowledge Base (Explicit & Local)

```
knowledge_base/
  australia.txt
  logistics_faq.txt
```

Example:

```
Australia's national government is based in Canberra.
Sydney is the largest city by population.
```

No hidden data. No magic.

---

### ğŸ” Retrieval

- TF-IDF (scikit-learn)
- Chunking + similarity ranking
- Top-K chunks injected into prompt

Why scikit-learn:
- transparent
- CPU-friendly
- no vector DB required

---

### ğŸ§  Key Lesson

Hallucinations are a **system design problem**, not a model bug.

---

## ğŸ§  App 3 â€” LangChain Orchestration (Multi-Step Reasoning)

ğŸ“„ **File:** `applications/langchain_orchestration.py`

Demonstrates explicit multi-step orchestration using LangChain.

---

### ğŸ” Pipeline

1. Classification  
2. Clarifying questions  
3. Checklist + required documents  
4. Optional email draft  

Each step:
- runs independently
- consumes prior output
- is visible in the UI

---

### ğŸ§  Key Lesson

Orchestration provides:
- control
- traceability
- debuggability

This mirrors real enterprise LLM workflows.

---

## ğŸ§  App 4 â€” MCP Tools Lab (Tool-Based Systems)

ğŸ“„ **File:** `applications/mcp_tax_tools.py`

Demonstrates tool-based LLM systems inspired by  
the Model Context Protocol (MCP).

---

### ğŸ§° Tools Implemented

1. classify_tax_case  
2. build_prep_checklist  
3. draft_tax_email  

Each tool is:
- deterministic
- typed
- auditable

---

### ğŸ“Š UI Shows

- live logs  
- progress bar  
- each tool call (inputs + outputs)  
- final composed result  

---

### ğŸ§  Key Lesson

Tools turn LLMs from  
**text generators**  
into  
**inspectable systems**

---

## ğŸ§  App 5 â€” Prompt Caching (Latency Optimization)

ğŸ“„ **File:** `applications/prompt_caching.py`

Demonstrates how **prompt caching** reduces latency by reusing  
previously computed model inputs.

---

### ğŸš€ What This App Shows

- Latency **before caching**
- Latency **after caching**
- Cache hit vs cache miss behavior
- Deterministic outputs reused safely

---

### ğŸ§  Why Prompt Caching Matters

Prompt caching:
- reduces response time
- lowers compute cost
- improves UX in multi-step pipelines

This is critical in:
- orchestration
- agents
- chat systems
- tool pipelines

---

## ğŸ§© How Everything Fits Together

| App | What It Teaches |
|---|---|
| Fine-tuning | Weight adaptation |
| Hallucinations | Why grounding is required |
| Orchestration | Structured reasoning |
| MCP Tools | Controlled execution |
| Prompt Caching | Latency optimization |

Together, they demonstrate modern LLM system design.

---

## â–¶ï¸ Running the Lab

```bash
python -m venv llms-venv
source llms-venv/bin/activate
python -m pip install -r requirements.txt
python -m streamlit run app.py
```

âš ï¸ Always use `python -m streamlit` to ensure the correct environment.

---

## ğŸš€ Roadmap

Planned additions:
- LoRA / QLoRA fine-tuning  
- Full RAG with embeddings  
- LangGraph workflows  
- MCP protocol integrations  
- Multi-agent coordination  
- ML & AI classics (trees, sparse regression, neural nets)  

---

## ğŸ§  Final Takeaway

This repository is not about making LLMs sound smart.

It is about understanding:
- why they fail
- how systems constrain them
- how engineers make them reliable

That is the difference between demos and production.

---

â­ If this repo helped you learn something â€” star it.  
ğŸ’¬ If youâ€™re hiring â€” this repo reflects how I think about AI systems.