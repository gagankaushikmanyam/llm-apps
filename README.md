Author: Gagan Kaushik Manyam  
---

# ğŸ§ª LLM Lab â€” A Systems-First Playground for Modern LLM Engineering

**LLM Lab** is a modular, Streamlit-based experimentation environment for learning and demonstrating  
**how real-world LLM systems are designed, debugged, and extended** â€” beyond prompts and demos.

This repository focuses on **system behavior**, not model hype.

It covers:
- supervised fine-tuning  
- hallucination mitigation  
- RAG-lite grounding  
- multi-step orchestration  
- tool-based (MCP-style) execution  

All examples are:
- **CPU-friendly**
- **fully inspectable**
- **explicit about failure modes**

This is a **learning + research lab**, not a production framework.

---

## ğŸ‘¤ Who This Repository Is For

This repo is designed for:

- **Aspiring AI / LLM Engineers** entering industry roles  
- **Software / ML Engineers** transitioning into LLM systems  
- **Researchers** who want to understand *why* LLMs fail or succeed  
- **Recruiters & hiring managers** evaluating practical system design skills  

If you want to understand:
- why hallucinations happen  
- why prompting is not enough  
- how orchestration actually works  
- how tools change LLM behavior  

this repo is for you.

---

## âœ¨ Design Principles

- ğŸ” **Inspectability over magic**
- ğŸ§  **Concept-first demos** (why things work or fail)
- ğŸ’» **CPU-first**, GPU optional
- ğŸ¯ **Reproducibility** (explicit seeds)
- ğŸ§© **Plugin-style architecture**
- ğŸš« No hidden datasets, no black boxes

---

## ğŸ— Architecture Overview

The lab is structured around a **single Streamlit launcher**:

```
app.py
```

Applications are auto-discovered from:

```
applications/
```

### ğŸ”Œ Application Contract

Every app must expose:

```python
APP_NAME = "Human-readable name"
APP_DESCRIPTION = "Optional description"

def run() -> None:
    ...
```

- Drop a new file into `applications/`
- Restart Streamlit
- No launcher changes required

This keeps the system **scalable and clean**.

---

# ğŸ§  App 1 â€” Hugging Face Fine-tuning (Supervised)

**File:** `applications/finetuning.py`

Demonstrates **end-to-end supervised fine-tuning** of a causal language model using  
**Hugging Face Transformers**.

---

## ğŸ¯ Task

Logistics email subject line generation from short instructions.

Example:

```
Instruction: Write an email subject for a shipment delayed due to weather.
Subject: Weather Delay: Updated ETA for Shipment (Arrives Tomorrow)
```

---

## ğŸ“Š What This App Shows

- True **before vs after** comparison  
- Validation loss + early stopping  
- Holdout benchmark (not seen during training)  
- Simple metrics:
  - Exact Match
  - Token-level F1  
- Saved artifacts:
  ```
  artifacts/finetuning/<timestamp>/
  ```

---

## ğŸ¤– Models

- `sshleifer/tiny-gpt2` â€” ultra-fast, educational  
- `distilgpt2` â€” higher quality, still CPU-friendly  

âš ï¸ This app performs **full fine-tuning**, not LoRA / QLoRA  
(LoRA/QLoRA are planned extensions.)

---

## ğŸ§  Key Lesson

Fine-tuning:
- improves **task alignment**
- does **not** inject knowledge
- overfits easily with small data

This app shows **what fine-tuning can and cannot do**.

---

# ğŸ§  App 2 â€” Hallucinations Lab (Prompting + RAG-lite)

**File:** `applications/hallucinations.py`

Demonstrates **why hallucinations happen** and why  
**grounding with context** is the only reliable mitigation.

---

## ğŸ”´ Baseline (Free-form)

**Characteristics**
- No structure  
- No refusal  
- No grounding  

Ask:
```
What year did Isaac Newton invent the smartphone?
```

You will get:
- fluent output  
- confident tone  
- fabricated content  

This is **default LLM behavior**.

---

## âš ï¸ Why Prompting Alone Is Not Enough

JSON-only, refusal, and self-consistency modes:
- improve **format**
- improve **stability**
- do **not** guarantee truth

**Key insight:**  
Prompting reduces chaos â€” **not hallucinations**.

---

## ğŸŸ¢ Context-Only Answering (RAG-lite)

The model:
- may **only** use retrieved context  
- must say `UNKNOWN` if unsupported  

This is a **minimal RAG system**.

---

## ğŸ“š Knowledge Base (Explicit & Local)

Directory structure:

```
knowledge_base/
â”œâ”€â”€ australia.txt
â”œâ”€â”€ logistics_faq.txt
```

Example (`australia.txt`):

```
Australia's national government is based in Canberra.
Sydney is the largest city by population.
```

No hidden data. No magic.

---

## ğŸ” Retrieval (RAG-lite)

- TF-IDF (scikit-learn)  
- Chunking + similarity ranking  
- Top-K chunks injected into the prompt  

**Why scikit-learn?**
- Transparent  
- CPU-friendly  
- No vector database required  

---

## ğŸ§  Key Lesson

Hallucinations are a **system design problem**, not a model bug.

---

# ğŸ§  App 3 â€” LangChain Orchestration (Multi-Step Reasoning)

**File:** `applications/langchain_orchestration.py`

Demonstrates **explicit multi-step orchestration** using LangChain.

---

## ğŸ” Pipeline

1. Classification  
2. Clarifying questions  
3. Checklist + required documents  
4. Optional email draft  

Each step:
- runs independently  
- consumes prior outputs  
- is visible in the UI  

---

## ğŸ§  Key Lesson

Orchestration provides:
- control  
- traceability  
- debuggability  

This mirrors **real enterprise LLM workflows**.

---

# ğŸ§  App 4 â€” MCP Tools Lab (Tool-Based Systems)

**File:** `applications/mcp_tax_tools.py`

Demonstrates **tool-based LLM systems** inspired by  
the **Model Context Protocol (MCP)**.

---

## ğŸ§° Tools Implemented

1. `classify_tax_case`  
2. `build_prep_checklist`  
3. `draft_tax_email`  

Each tool is:
- deterministic  
- typed  
- auditable  

---

## ğŸ“Š UI Highlights

- Live logs  
- Progress bar  
- Each tool call (inputs + outputs)  
- Final composed result  

---

## ğŸ§  Key Lesson

Tools turn LLMs from:

> *text generators*  

into:

> **inspectable systems**

---

## ğŸ§© How Everything Fits Together

| Application | What It Teaches |
|------------|----------------|
| Fine-tuning | Weight adaptation |
| Hallucinations | Why grounding is required |
| Orchestration | Structured reasoning |
| MCP Tools | Controlled execution |

Together, these demonstrate **modern LLM system design**.

---

## â–¶ï¸ Running the Lab

```bash
python -m venv llms-venv
source llms-venv/bin/activate
python -m pip install -r requirements.txt
python -m streamlit run app.py
```

âš ï¸ Always use `python -m streamlit` to ensure the correct environment.

---

## ğŸš€ Roadmap

Planned additions:
- LoRA / QLoRA fine-tuning  
- Full RAG with embeddings  
- LangGraph workflows  
- MCP protocol integrations  
- Multi-agent coordination  
- ML & AI classics (decision trees, sparse regression, neural nets)  

---

## ğŸ§  Final Takeaway

This repository is not about making LLMs sound smart.

It is about understanding:
- why they fail  
- how systems constrain them  
- how engineers make them reliable  

That is the difference between **demos** and **production**.

---

â­ If this repo helped you learn something â€” **star it**.  
ğŸ’¬ If youâ€™re hiring â€” this repo reflects **how I think about AI systems**.