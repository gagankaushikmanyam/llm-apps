
â¸»
Author: Gagan Kaushik Manyam  
---

# ğŸ§ª LLM Lab â€” A Systems-First Playground for Modern LLM Engineering

**LLM Lab** is a modular, Streamlit-based experimentation environment for learning and demonstrating  
**how real-world LLM systems are designed, debugged, and extended** â€” beyond prompts and demos.

This repository focuses on **system behavior**, not model hype.

It covers:
- supervised fine-tuning
- hallucination mitigation
- RAG-lite grounding
- multi-step orchestration
- tool-based (MCP-style) execution

All examples are:
- **CPU-friendly**
- **fully inspectable**
- **explicit about failure modes**

This is a **learning + research lab**, not a production framework.

---

## ğŸ‘¤ Who This Repository Is For

This repo is designed for:

- **Aspiring AI / LLM Engineers** entering industry roles  
- **Software / ML Engineers** transitioning into LLM systems  
- **Researchers** who want to understand *why* LLMs fail or succeed  
- **Recruiters & hiring managers** evaluating practical system design skills  

If you want to understand:
- why hallucinations happen,
- why prompting is not enough,
- how orchestration actually works,
- how tools change LLM behavior,

this repo is for you.

---

## âœ¨ Design Principles

- ğŸ” **Inspectability over magic**
- ğŸ§  **Concept-first demos** (why things work or fail)
- ğŸ’» **CPU-first**, GPU optional
- ğŸ¯ **Reproducibility** (explicit seeds)
- ğŸ§© **Plugin-style architecture**
- ğŸš« No hidden datasets, no black boxes

---

## ğŸ— Architecture Overview

The lab is structured around a **single Streamlit launcher**:

app.py

Applications are auto-discovered from:

applications/

### ğŸ”Œ Application Contract

Every app must expose:

```python
APP_NAME = "Human-readable name"
APP_DESCRIPTION = "Optional description"

def run() -> None:
    ...

â¡ï¸ Drop a new file into applications/
â¡ï¸ Restart Streamlit
â¡ï¸ No launcher changes required

This keeps the system scalable and clean.

â¸»

ğŸ§  App 1 â€” Hugging Face Fine-tuning (Supervised)

ğŸ“„ File: applications/finetuning.py

Demonstrates end-to-end supervised fine-tuning of a causal language model using
Hugging Face Transformers.

â¸»

ğŸ¯ Task

Logistics email subject line generation from short instructions.

Instruction: Write an email subject for a shipment delayed due to weather.
Subject: Weather Delay: Updated ETA for Shipment (Arrives Tomorrow)


â¸»

ğŸ“Š What This App Shows
	â€¢	TRUE before vs after comparison
	â€¢	Validation loss + early stopping
	â€¢	Holdout benchmark (not seen during training)
	â€¢	Simple metrics:
	â€¢	Exact Match
	â€¢	Token-level F1
	â€¢	Saved artifacts:

artifacts/finetuning/<timestamp>/



â¸»

ğŸ¤– Models
	â€¢	sshleifer/tiny-gpt2 â€” ultra-fast, educational
	â€¢	distilgpt2 â€” higher quality, still CPU-friendly

âš ï¸ This app performs full fine-tuning, not LoRA / QLoRA
(LoRA/QLoRA are planned extensions.)

â¸»

ğŸ§  Key Lesson

Fine-tuning:
	â€¢	improves task alignment
	â€¢	does NOT inject knowledge
	â€¢	overfits easily with small data

This app shows what fine-tuning can and cannot do.

â¸»

ğŸ§  App 2 â€” Hallucinations Lab (Prompting + RAG-lite)

ğŸ“„ File: applications/hallucinations.py

Demonstrates why hallucinations happen and why
grounding with context is the only reliable mitigation.

â¸»

ğŸ”´ Baseline (Free-form)
	â€¢	No structure
	â€¢	No refusal
	â€¢	No grounding

Ask:

What year did Isaac Newton invent the smartphone?

Youâ€™ll get:
	â€¢	fluent
	â€¢	confident
	â€¢	fabricated answers

This is default LLM behavior.

â¸»

âš ï¸ Prompting Alone Is Not Enough

JSON-only, refusal, self-consistency:
	â€¢	improve format
	â€¢	improve stability
	â€¢	do NOT guarantee truth

Prompting reduces chaos â€” not hallucinations.

â¸»

ğŸŸ¢ Context-Only Answering (RAG-lite)

The model:
	â€¢	may ONLY use retrieved context
	â€¢	must say UNKNOWN if unsupported

This is a minimal RAG system.

â¸»

ğŸ“š Knowledge Base (Explicit & Local)

knowledge_base/
  australia.txt
  logistics_faq.txt

Example:

Australia's national government is based in Canberra.
Sydney is the largest city by population.

No hidden data. No magic.

â¸»

ğŸ” Retrieval
	â€¢	TF-IDF (scikit-learn)
	â€¢	Chunking + similarity ranking
	â€¢	Top-K chunks injected into prompt

Why scikit-learn?
	â€¢	Transparent
	â€¢	CPU-friendly
	â€¢	No vector DB required

â¸»

ğŸ§  Key Lesson

Hallucinations are a system design problem, not a model bug.

â¸»

ğŸ§  App 3 â€” LangChain Orchestration (Multi-Step Reasoning)

ğŸ“„ File: applications/langchain_orchestration.py

Demonstrates explicit multi-step orchestration using LangChain.

â¸»

ğŸ” Pipeline
	1.	Classification
	2.	Clarifying questions
	3.	Checklist + required documents
	4.	Optional email draft

Each step:
	â€¢	runs independently
	â€¢	consumes prior output
	â€¢	is visible in the UI

â¸»

ğŸ§  Key Lesson

Orchestration provides:
	â€¢	control
	â€¢	traceability
	â€¢	debuggability

This mirrors real enterprise LLM workflows.

â¸»

ğŸ§  App 4 â€” MCP Tools Lab (Tool-Based Systems)

ğŸ“„ File: applications/mcp_tax_tools.py

Demonstrates tool-based LLM systems inspired by
the Model Context Protocol (MCP).

â¸»

ğŸ§° Tools Implemented
	1.	classify_tax_case
	2.	build_prep_checklist
	3.	draft_tax_email

Each tool is:
	â€¢	deterministic
	â€¢	typed
	â€¢	auditable

â¸»

ğŸ“Š UI Shows
	â€¢	live logs
	â€¢	progress bar
	â€¢	each tool call (inputs + outputs)
	â€¢	final composed result

â¸»

ğŸ§  Key Lesson

Tools turn LLMs from:

â€œtext generatorsâ€
into
inspectable systems

â¸»

ğŸ§© How Everything Fits Together

App	What It Teaches
Fine-tuning	Weight adaptation
Hallucinations	Why grounding is required
Orchestration	Structured reasoning
MCP Tools	Controlled execution

Together, they demonstrate modern LLM system design.

â¸»

â–¶ï¸ Running the Lab

python -m venv llms-venv
source llms-venv/bin/activate
python -m pip install -r requirements.txt
python -m streamlit run app.py

âš ï¸ Always use python -m streamlit to ensure the correct environment.

â¸»

ğŸš€ Roadmap

Planned additions:
	â€¢	LoRA / QLoRA fine-tuning
	â€¢	Full RAG with embeddings
	â€¢	LangGraph workflows
	â€¢	MCP protocol integrations
	â€¢	Multi-agent coordination
	â€¢	ML & AI classics (trees, sparse regression, neural nets)

â¸»

ğŸ§  Final Takeaway

This repository is not about making LLMs sound smart.

It is about understanding:
	â€¢	why they fail
	â€¢	how systems constrain them
	â€¢	how engineers make them reliable

That is the difference between demos and production.

â¸»

â­ If this repo helped you learn something â€” star it.
ğŸ’¬ If youâ€™re hiring â€” this repo reflects how I think about AI systems.

---