â¸»


# LLM Lab ðŸ§ª

A lightweight, scalable **Streamlit-based playground** for experimenting with Large Language Model (LLM) techniques such as **fine-tuning**, with a structure that allows adding more apps (LoRA, QLoRA, RAG, MCP) later.

---

## Streamlit App Overview

This repository runs a **single Streamlit launcher (`app.py`)** that automatically discovers and loads mini-apps from the `applications/` folder.

### How it works
- `app.py` scans `applications/*.py`
- Each app must define:
  ```python
  APP_NAME = "Readable App Name"

  def run() -> None:
      ...

	â€¢	Every discovered app appears automatically in the left sidebar
	â€¢	Selecting an app renders its UI in the main panel

This design allows you to add new LLM experiments by simply adding a new file to applications/ â€” no changes to the launcher are required.

â¸»

App Included: Hugging Face Fine-tuning Demo

File: applications/finetuning.py
Goal: Demonstrate before vs after behavior when fine-tuning a language model on a small, task-specific dataset.

The app shows:
	â€¢	Model output before fine-tuning
	â€¢	Model output after fine-tuning
	â€¢	Training loss per epoch
	â€¢	Saved fine-tuned model artifacts

â¸»

What is Fine-tuning?

Pretrained language models (like GPT-2) are trained on large, general datasets.
They understand language broadly, but they are not specialized for your exact task.

Fine-tuning means:

Continuing training on a small, task-specific dataset so the model adapts its behavior.

Fine-tuning changes the modelâ€™s weights, unlike prompt engineering, which only changes the input text.

â¸»

How Fine-tuning is done in this repo (Toy Example)

Task

Generate logistics email subject lines from short instructions.

Example input

Write an email subject for a shipment delayed due to weather.
Mention the new ETA is tomorrow.

Target output

Weather Delay: Updated ETA for Shipment (Arrives Tomorrow)


â¸»

Dataset
	â€¢	The dataset is defined in utils/io.py
	â€¢	Each example contains:
	â€¢	instruction â€“ what the email is about
	â€¢	subject â€“ the correct subject line
	â€¢	The dataset is intentionally very small so training runs quickly on CPU

This is a learning/demo dataset, not a production one.

â¸»

Model
	â€¢	Default model: sshleifer/tiny-gpt2
	â€¢	Very small
	â€¢	CPU-friendly
	â€¢	Chosen to make fine-tuning fast and visible
	â€¢	Optional upgrade: distilgpt2
	â€¢	Better quality
	â€¢	Slower on CPU

Models are loaded from Hugging Face Transformers.

â¸»

Training process (simplified)
	1.	Each example is formatted as:

Instruction: <instruction>
Subject: <subject>


	2.	Text is tokenized into model inputs
	3.	The model is trained using Hugging Faceâ€™s Trainer API
	4.	Training runs for a small number of epochs
	5.	The fine-tuned model is saved locally under:

artifacts/finetuning/<timestamp>/



â¸»

Generation (Before vs After)

The same instruction is run:
	â€¢	Once with the base pretrained model
	â€¢	Once with the fine-tuned model

This makes it easy to see how fine-tuning changes model behavior.

To reduce repetition caused by tiny datasets, generation uses:
	â€¢	Greedy or beam decoding
	â€¢	Repetition penalties
	â€¢	No-repeat n-gram constraints

â¸»

Running the App

python -m venv llms-venv
source llms-venv/bin/activate
python -m pip install -r requirements.txt
python -m streamlit run app.py

Always use python -m streamlit to ensure the correct virtual environment is used.

â¸»

Extending the Lab

To add a new experiment:
	1.	Create a new file in applications/
	2.	Define APP_NAME and run()
	3.	Restart Streamlit

The README can be extended by adding short sections for new apps as they are added.

â¸»

Purpose of this Repo

This project focuses on understanding the mechanics of LLM fine-tuning and experimentation â€” not on producing perfect text.

Once these fundamentals are clear, extending to LoRA, QLoRA, RAG, or agent systems becomes straightforward.

---

